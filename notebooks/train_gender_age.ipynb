{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# https://susanqq.github.io/UTKFace/\n\nimport os\nimport warnings\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom tqdm.notebook import tqdm\n\nwarnings.filterwarnings('ignore') #Clean result\n%matplotlib inline\n\nimport random\nimport shutil\nimport zipfile\n\n%load_ext tensorboard\n\nimport tensorflow as tf\nfrom keras.layers import Conv2D, Dense, Dropout, Flatten, Input, MaxPooling2D\nfrom keras.models import Model, Sequential\nfrom keras.preprocessing.image import load_img\nfrom PIL import Image\n\n# plot the model\nfrom tensorflow.keras.utils import plot_model","metadata":{"execution":{"iopub.status.busy":"2022-07-21T03:05:03.139888Z","iopub.execute_input":"2022-07-21T03:05:03.140408Z","iopub.status.idle":"2022-07-21T03:05:10.600709Z","shell.execute_reply.started":"2022-07-21T03:05:03.140316Z","shell.execute_reply":"2022-07-21T03:05:10.599590Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"BASE_DIR = '/kaggle/input/utkface-new/UTKFace/'  # basic directory to load the image or the data","metadata":{"execution":{"iopub.status.busy":"2022-07-21T03:05:29.634314Z","iopub.execute_input":"2022-07-21T03:05:29.634984Z","iopub.status.idle":"2022-07-21T03:05:29.639664Z","shell.execute_reply.started":"2022-07-21T03:05:29.634948Z","shell.execute_reply":"2022-07-21T03:05:29.638672Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# map labels for gender and race\ngender_dict = {0:'Male', 1:'Female'}\nrace_dict={0:'White', 1:'Black',2:'Asian',3:'Indian',4:'Others (like Hispanic, Latino, Middle Eastern)'}\n\n# labels - age, gender, ethnicity\nimage_paths, age_labels, gender_labels, race_labels = [], [], [], []\n\n# cleanup data by removing the images that dont have all the labels after split\nfor filename in tqdm(os.listdir(BASE_DIR)):\n  try:\n      temp = filename.split('_')\n      race= int(temp[2])\n      image_path = os.path.join(BASE_DIR, filename)\n      age = int(temp[0])\n      gender = int(temp[1])\n      image_paths.append(image_path)\n      age_labels.append(age)\n      gender_labels.append(gender)\n      race_labels.append(race)\n  except Exception as e:\n    print(f\"ERROR: {filename}: {e}\")","metadata":{"execution":{"iopub.status.busy":"2022-07-21T03:05:40.195922Z","iopub.execute_input":"2022-07-21T03:05:40.196329Z","iopub.status.idle":"2022-07-21T03:05:40.989747Z","shell.execute_reply.started":"2022-07-21T03:05:40.196299Z","shell.execute_reply":"2022-07-21T03:05:40.988753Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# convert to dataframe\ndf = pd.DataFrame()\ndf['image'], df['age'], df['gender'],df['race']= image_paths, age_labels, gender_labels, race_labels\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-21T03:07:29.531431Z","iopub.execute_input":"2022-07-21T03:07:29.531885Z","iopub.status.idle":"2022-07-21T03:07:29.587115Z","shell.execute_reply.started":"2022-07-21T03:07:29.531850Z","shell.execute_reply":"2022-07-21T03:07:29.586094Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## Exploring the data","metadata":{}},{"cell_type":"code","source":"# Display only one image\nimg = Image.open(df['image'][0])  # Just loading the first image\nplt.axis('off')\nplt.imshow(img);","metadata":{"execution":{"iopub.status.busy":"2022-07-21T03:07:36.920945Z","iopub.execute_input":"2022-07-21T03:07:36.921356Z","iopub.status.idle":"2022-07-21T03:07:37.117969Z","shell.execute_reply.started":"2022-07-21T03:07:36.921324Z","shell.execute_reply":"2022-07-21T03:07:37.117217Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"sns.distplot(df['age'])","metadata":{"execution":{"iopub.status.busy":"2022-07-20T14:37:50.505502Z","iopub.execute_input":"2022-07-20T14:37:50.505887Z","iopub.status.idle":"2022-07-20T14:37:50.974005Z","shell.execute_reply.started":"2022-07-20T14:37:50.505857Z","shell.execute_reply":"2022-07-20T14:37:50.972783Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"sns.countplot(df['gender'])","metadata":{"execution":{"iopub.status.busy":"2022-07-20T14:37:56.502565Z","iopub.execute_input":"2022-07-20T14:37:56.502989Z","iopub.status.idle":"2022-07-20T14:37:56.677974Z","shell.execute_reply.started":"2022-07-20T14:37:56.502954Z","shell.execute_reply":"2022-07-20T14:37:56.676656Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"sns.countplot(df['race'])","metadata":{"execution":{"iopub.status.busy":"2022-07-20T14:37:58.470073Z","iopub.execute_input":"2022-07-20T14:37:58.470705Z","iopub.status.idle":"2022-07-20T14:37:58.654633Z","shell.execute_reply.started":"2022-07-20T14:37:58.470659Z","shell.execute_reply":"2022-07-20T14:37:58.653829Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# to display grid of images\nplt.figure(figsize=(20, 20))\nfiles = df.iloc[0:25]\n\nfor index, file, age, gender, race in files.itertuples():\n    plt.subplot(5, 5, index+1)\n    img = load_img(file)\n    plt.imshow(np.array(img), cmap='gray')\n    plt.title(f\"Age: {age}\\nGender: {gender_dict[gender]}\\nRace:{race_dict[race]}\")\n    plt.axis('off')","metadata":{"execution":{"iopub.status.busy":"2022-07-21T03:07:44.408075Z","iopub.execute_input":"2022-07-21T03:07:44.408512Z","iopub.status.idle":"2022-07-21T03:07:46.670941Z","shell.execute_reply.started":"2022-07-21T03:07:44.408479Z","shell.execute_reply":"2022-07-21T03:07:46.669710Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## Feature Extraction","metadata":{}},{"cell_type":"code","source":"# Functions\ndef extract_features(images):\n    features = []\n    for image in tqdm(images):\n        img = load_img(image, grayscale=True)      \n        img = img.resize((128, 128), Image.ANTIALIAS)\n        img = np.array(img)\n        features.append(img)\n        \n    features = np.array(features)   # convert the features to numpy array, CNN can handle np.array\n    # ignore this step if using RGB\n    features = features.reshape(len(features), 128, 128, 1) \n    return features","metadata":{"execution":{"iopub.status.busy":"2022-07-21T03:08:16.116237Z","iopub.execute_input":"2022-07-21T03:08:16.116659Z","iopub.status.idle":"2022-07-21T03:08:16.124374Z","shell.execute_reply.started":"2022-07-21T03:08:16.116628Z","shell.execute_reply":"2022-07-21T03:08:16.123246Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"X = extract_features(df['image'])\nX.shape\n\n# normalize the images\nX = X/255.0                 # the pixel value is 0 to 255, normalizing will be in the range 0 to 1\n\ny_gender = np.array(df['gender'])\ny_age = np.array(df['age'])\ny_race=np.array(df['race'])\n\ninput_shape = (128, 128, 1)","metadata":{"execution":{"iopub.status.busy":"2022-07-21T03:08:37.135972Z","iopub.execute_input":"2022-07-21T03:08:37.136447Z","iopub.status.idle":"2022-07-21T03:12:31.755130Z","shell.execute_reply.started":"2022-07-21T03:08:37.136402Z","shell.execute_reply":"2022-07-21T03:12:31.754397Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"inputs = Input((input_shape))       # image as an input. And getting 2 output: classification and regresssion\n# convolutional layers\nconv_1 = Conv2D(32, kernel_size=(3, 3), activation='relu') (inputs)  # this activation layer improves the model performance\nmaxp_1 = MaxPooling2D(pool_size=(2, 2)) (conv_1)                     # conv_1 is output, just passing here at as input\nconv_2 = Conv2D(64, kernel_size=(3, 3), activation='relu') (maxp_1)\nmaxp_2 = MaxPooling2D(pool_size=(2, 2)) (conv_2)\nconv_3 = Conv2D(128, kernel_size=(3, 3), activation='relu') (maxp_2)\nmaxp_3 = MaxPooling2D(pool_size=(2, 2)) (conv_3)\nconv_4 = Conv2D(256, kernel_size=(3, 3), activation='relu') (maxp_3)\nmaxp_4 = MaxPooling2D(pool_size=(2, 2)) (conv_4)\n\nflatten = Flatten() (maxp_4)  # flatten is conventional layers heve weight in terms of matrix structure, so flattern convert to single dimension\n\n# fully connected layers\ndense_1 = Dense(256, activation='relu') (flatten)\ndense_2 = Dense(256, activation='relu') (flatten)\n# dense_3 = Dense(256, activation='relu') (flatten)\n\ndropout_1 = Dropout(0.3) (dense_1)\ndropout_2 = Dropout(0.3) (dense_2)\n# dropout_3 = Dropout(0.3) (dense_3)\n\noutput_1 = Dense(1, activation='sigmoid', name='gender_out') (dropout_1)\noutput_2 = Dense(1, activation='relu', name='age_out') (dropout_2)\n# output_3 = Dense(1, activation='softmax', name='race_out') (dropout_3)\n\n# model = Model(inputs=[inputs], outputs=[output_1,output_2,output_3])\nmodel = Model(inputs=[inputs], outputs=[output_1, output_2])\n\nmodel.compile(loss=['binary_crossentropy', 'mae'], optimizer='adam', metrics=['accuracy'])  # binary_crossentropy for gender (classification), mae for age (regression)","metadata":{"execution":{"iopub.status.busy":"2022-07-21T03:15:06.239591Z","iopub.execute_input":"2022-07-21T03:15:06.241134Z","iopub.status.idle":"2022-07-21T03:15:06.384171Z","shell.execute_reply.started":"2022-07-21T03:15:06.241082Z","shell.execute_reply":"2022-07-21T03:15:06.383171Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-07-21T03:15:19.702029Z","iopub.execute_input":"2022-07-21T03:15:19.703174Z","iopub.status.idle":"2022-07-21T03:15:19.713620Z","shell.execute_reply.started":"2022-07-21T03:15:19.703117Z","shell.execute_reply":"2022-07-21T03:15:19.712197Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"plot_model(model)","metadata":{"execution":{"iopub.status.busy":"2022-07-21T03:15:21.952475Z","iopub.execute_input":"2022-07-21T03:15:21.953034Z","iopub.status.idle":"2022-07-21T03:15:23.569837Z","shell.execute_reply.started":"2022-07-21T03:15:21.952987Z","shell.execute_reply":"2022-07-21T03:15:23.568595Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"checkpoint_path = '/kaggle/working/cp_03.ckpt'\ncheckpoint_dir = os.path.dirname(checkpoint_path)\n# Create a callback that saves the model's weights\ncp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n                                                 save_weights_only=True,\n                                                 verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-07-21T03:15:44.004468Z","iopub.execute_input":"2022-07-21T03:15:44.004940Z","iopub.status.idle":"2022-07-21T03:15:44.012066Z","shell.execute_reply.started":"2022-07-21T03:15:44.004900Z","shell.execute_reply":"2022-07-21T03:15:44.010774Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# train model\nhistory = model.fit(x=X, y=[y_gender, y_age], batch_size=32, epochs=5, validation_split=0.2, callbacks=[cp_callback]) # Pass callback to training","metadata":{"execution":{"iopub.status.busy":"2022-07-21T03:16:02.214141Z","iopub.execute_input":"2022-07-21T03:16:02.215118Z","iopub.status.idle":"2022-07-21T03:37:27.281605Z","shell.execute_reply.started":"2022-07-21T03:16:02.215081Z","shell.execute_reply":"2022-07-21T03:37:27.280639Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# test_generator = ImageDataGenerator()\n# test_data_generator = test_generator.flow_from_directory(\n#     test_data_path, # Put your path here\n#      target_size=(img_width, img_height),\n#     batch_size=32,\n#     shuffle=False)\n# test_steps_per_epoch = numpy.math.ceil(test_data_generator.samples / test_data_generator.batch_size)\n\n# predictions = model.predict_generator(test_data_generator, steps=test_steps_per_epoch)\n\n# # Get most likely class\n# predicted_classes = numpy.argmax(predictions, axis=1)\n\n# X_test = X\n# predictions = model.predict(X_test)\n# predictions\n# y_pred = (predictions > 0.5)\n# y_pred\n\n# matrix = metrics.confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))\n\n\n# from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n\n# y_true = [1, 1, 0, 0, 0, 1]\n# y_pred = [0, 0, 1, 1, 0, 1]\n# cm = confusion_matrix(y_true, y_pred)\n# disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n# disp.plot()\n\ny_true = []\ny_pred = []\nvals = [index for index, file, age, gender, race in df.itertuples()]\n# vals = [index for index, file, age, gender, race in files.itertuples()]\nfor i, index in enumerate(np.random.choice(vals, size=500, replace=False)):\n# for i, index in enumerate(vals):\n#     print(i)\n    pred = model.predict(X[index].reshape(1, 128, 128, 1))\n    pred_gender = gender_dict[round(pred[0][0][0])]\n    orig_gender = gender_dict[y_gender[index]]\n    if orig_gender == \"Male\":\n        y_true.append(1)\n    else:\n        y_true.append(0)\n    if pred_gender == \"Male\":\n        y_pred.append(1)\n    else:\n        y_pred.append(0)\n# print(y_true)\n# print(y_pred)\ncm = confusion_matrix(y_true, y_pred)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm)\ndisp.plot()\n\n#     print(orig_gender, pred_gender)\n    \n# for i, index in enumerate(np.random.choice(vals, size=15, replace=False)):\n#     predict_image(index, X, model)\n#     pred = model.predict(X[image_index].reshape(1, 128, 128, 1))\n#     pred_gender = gender_dict[round(pred[0][0][0])]","metadata":{"execution":{"iopub.status.busy":"2022-07-20T14:17:28.566725Z","iopub.execute_input":"2022-07-20T14:17:28.567538Z","iopub.status.idle":"2022-07-20T14:17:28.674992Z","shell.execute_reply.started":"2022-07-20T14:17:28.567387Z","shell.execute_reply":"2022-07-20T14:17:28.673988Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"saved_model_path = '/kaggle/working/saved_model_20Jul2022_02.h5'\nmodel.save(saved_model_path)\n\n# saved_model_path = \"/kaggle/input/model-data/saved_model_02.h5\"\n# model = tf.keras.models.load_model(saved_model_path)\n# new_model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-07-20T09:54:22.494513Z","iopub.execute_input":"2022-07-20T09:54:22.495439Z","iopub.status.idle":"2022-07-20T09:54:22.684572Z","shell.execute_reply.started":"2022-07-20T09:54:22.495399Z","shell.execute_reply":"2022-07-20T09:54:22.683486Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# plot results for gender\nacc = history.history['gender_out_accuracy']\nval_acc = history.history['val_gender_out_accuracy']\nepochs = range(len(acc))    # can getting the number of epochs\n\nplt.plot(epochs, acc, 'b', label='Training Accuracy')        # 'b' is blue\nplt.plot(epochs, val_acc, 'r', label='Validation Accuracy')  # 'r' is red\nplt.title('Accuracy Graph')\nplt.legend()\nplt.figure()\n\nloss = history.history['gender_out_loss']\nval_loss = history.history['val_gender_out_loss']\n\nplt.plot(epochs, loss, 'b', label='Training Loss')\nplt.plot(epochs, val_loss, 'r', label='Validation Loss')\nplt.title('Loss Graph')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-20T09:59:41.051250Z","iopub.execute_input":"2022-07-20T09:59:41.051726Z","iopub.status.idle":"2022-07-20T09:59:41.483586Z","shell.execute_reply.started":"2022-07-20T09:59:41.051689Z","shell.execute_reply":"2022-07-20T09:59:41.482612Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# plot results for age\nloss = history.history['age_out_loss']\nval_loss = history.history['val_age_out_loss']\nepochs = range(len(loss))\n\nplt.plot(epochs, loss, 'b', label='Training Loss')\nplt.plot(epochs, val_loss, 'r', label='Validation Loss')\nplt.title('Loss Graph')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-20T09:59:44.273050Z","iopub.execute_input":"2022-07-20T09:59:44.274043Z","iopub.status.idle":"2022-07-20T09:59:44.426853Z","shell.execute_reply.started":"2022-07-20T09:59:44.273990Z","shell.execute_reply":"2022-07-20T09:59:44.426218Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"### Prediction with Test Data","metadata":{}},{"cell_type":"code","source":"def predict_image(image_index, X, model):\n    print(\n        \"Original Gender:\", gender_dict[y_gender[image_index]],\n        \"Original Age:\", y_age[image_index]\n    )\n    # predict from model\n    pred = model.predict(X[image_index].reshape(1, 128, 128, 1))\n    pred_gender = gender_dict[round(pred[0][0][0])]\n    pred_age = round(pred[1][0][0])\n    print(\n        \"Predicted Gender:\", pred_gender,\n        \"Predicted Age:\", pred_age\n    )\n    plt.axis('off')\n    plt.imshow(X[image_index].reshape(128, 128), cmap='gray')\n    plt.show()\n\nvals = [index for index, file, age, gender, race in files.itertuples()]\nfor i, index in enumerate(np.random.choice(vals, size=15, replace=False)):\n    predict_image(index, X, model)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T09:59:47.259767Z","iopub.execute_input":"2022-07-20T09:59:47.260680Z","iopub.status.idle":"2022-07-20T09:59:50.153764Z","shell.execute_reply.started":"2022-07-20T09:59:47.260646Z","shell.execute_reply":"2022-07-20T09:59:50.152672Z"},"trusted":true},"execution_count":27,"outputs":[]}]}