{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-07-21T11:54:04.491995Z","iopub.status.busy":"2022-07-21T11:54:04.491320Z","iopub.status.idle":"2022-07-21T11:54:12.755885Z","shell.execute_reply":"2022-07-21T11:54:12.754379Z","shell.execute_reply.started":"2022-07-21T11:54:04.491940Z"},"trusted":true},"outputs":[],"source":["import os\n","import warnings\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","from tqdm.notebook import tqdm\n","\n","warnings.filterwarnings('ignore') #Clean result\n","%matplotlib inline\n","\n","import random\n","import shutil\n","import zipfile\n","\n","%load_ext tensorboard\n","\n","import tensorflow as tf\n","from keras.layers import Conv2D, Dense, Dropout, Flatten, Input, MaxPooling2D, InputLayer\n","from keras.models import Model, Sequential\n","from keras.preprocessing.image import load_img\n","from PIL import Image\n","\n","# plot the model\n","from tensorflow.keras.utils import plot_model\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-07-21T11:54:12.768597Z","iopub.status.busy":"2022-07-21T11:54:12.767564Z","iopub.status.idle":"2022-07-21T11:54:12.780117Z","shell.execute_reply":"2022-07-21T11:54:12.778965Z","shell.execute_reply.started":"2022-07-21T11:54:12.768527Z"},"trusted":true},"outputs":[],"source":["BASE_DIR = '/input/utkface-new/UTKFace/'  # basic directory to load the image or the data"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-07-21T11:54:12.783277Z","iopub.status.busy":"2022-07-21T11:54:12.782576Z","iopub.status.idle":"2022-07-21T11:54:13.427671Z","shell.execute_reply":"2022-07-21T11:54:13.426449Z","shell.execute_reply.started":"2022-07-21T11:54:12.783238Z"},"trusted":true},"outputs":[],"source":["# map labels for gender and race\n","gender_dict = {0:'Male', 1:'Female'}\n","race_dict={0:'White', 1:'Black',2:'Asian',3:'Indian',4:'Others (like Hispanic, Latino, Middle Eastern)'}\n","\n","# labels - age, gender, ethnicity\n","image_paths, age_labels, gender_labels, race_labels = [], [], [], []\n","\n","# cleanup data by removing the images that dont have all the labels after split\n","for filename in tqdm(os.listdir(BASE_DIR)):\n","  try:\n","      temp = filename.split('_')\n","      race= int(temp[2])\n","      image_path = os.path.join(BASE_DIR, filename)\n","      age = int(temp[0])\n","      gender = int(temp[1])\n","      image_paths.append(image_path)\n","      age_labels.append(age)\n","      gender_labels.append(gender)\n","      race_labels.append(race)\n","  except Exception as e:\n","    print(f\"ERROR: {filename}: {e}\")"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-07-21T11:54:14.683988Z","iopub.status.busy":"2022-07-21T11:54:14.683306Z","iopub.status.idle":"2022-07-21T11:54:14.762014Z","shell.execute_reply":"2022-07-21T11:54:14.760981Z","shell.execute_reply.started":"2022-07-21T11:54:14.683946Z"},"trusted":true},"outputs":[],"source":["# convert to dataframe\n","df = pd.DataFrame()\n","df['image'], df['age'], df['gender'],df['race']= image_paths, age_labels, gender_labels, race_labels\n","df.head()"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2022-07-21T13:17:44.560684Z","iopub.status.busy":"2022-07-21T13:17:44.559720Z","iopub.status.idle":"2022-07-21T13:17:46.876395Z","shell.execute_reply":"2022-07-21T13:17:46.872816Z","shell.execute_reply.started":"2022-07-21T13:17:44.560614Z"},"trusted":true},"outputs":[],"source":["# to display grid of images\n","plt.figure(figsize=(20, 20))\n","files = df.iloc[0:25]\n","\n","for index, file, age, gender, race in files.itertuples():\n","    plt.subplot(5, 5, index+1)\n","    img = load_img(file)\n","    plt.imshow(np.array(img), cmap='gray')\n","    plt.title(f\"Age: {age}\\nGender: {gender_dict[gender]}\\nRace:{race_dict[race]}\")\n","    plt.axis('off')"]},{"cell_type":"markdown","metadata":{},"source":["## Feature Extraction"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2022-07-21T11:54:23.754106Z","iopub.status.busy":"2022-07-21T11:54:23.752920Z","iopub.status.idle":"2022-07-21T11:54:23.762229Z","shell.execute_reply":"2022-07-21T11:54:23.760630Z","shell.execute_reply.started":"2022-07-21T11:54:23.754041Z"},"trusted":true},"outputs":[],"source":["# Functions\n","def extract_features(images):\n","    features = []\n","    for image in tqdm(images):\n","        img = load_img(image, grayscale=True)      \n","        img = img.resize((128, 128), Image.ANTIALIAS)\n","        img = np.array(img)\n","        features.append(img)\n","        \n","    features = np.array(features)   # convert the features to numpy array, CNN can handle np.array\n","    # ignore this step if using RGB\n","    features = features.reshape(len(features), 128, 128, 1) \n","    return features"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2022-07-21T11:54:25.354611Z","iopub.status.busy":"2022-07-21T11:54:25.354059Z","iopub.status.idle":"2022-07-21T11:56:32.862430Z","shell.execute_reply":"2022-07-21T11:56:32.860974Z","shell.execute_reply.started":"2022-07-21T11:54:25.354567Z"},"trusted":true},"outputs":[],"source":["X = extract_features(df['image'])\n","X.shape\n","\n","# normalize the images\n","X = X/255.0 # the pixel value is 0 to 255, normalizing will be in the range 0 to 1\n","\n","y_gender = np.array(df['gender'])\n","y_age = np.array(df['age'])\n","y_race=np.array(df['race'])\n","\n","input_shape = (128, 128, 1)"]},{"cell_type":"markdown","metadata":{},"source":["## Model building"]},{"cell_type":"code","execution_count":64,"metadata":{"execution":{"iopub.execute_input":"2022-07-21T13:45:28.763696Z","iopub.status.busy":"2022-07-21T13:45:28.763001Z","iopub.status.idle":"2022-07-21T13:45:28.925794Z","shell.execute_reply":"2022-07-21T13:45:28.924551Z","shell.execute_reply.started":"2022-07-21T13:45:28.763645Z"},"trusted":true},"outputs":[],"source":["inputs = Input((input_shape))       # image as an input. And getting 2 output: classification and regresssion\n","# convolutional layers\n","conv_1 = Conv2D(32, kernel_size=(3, 3), activation='relu') (inputs)  # this activation layer improves the model performance\n","maxp_1 = MaxPooling2D(pool_size=(2, 2)) (conv_1)                     # conv_1 is output, just passing here at as input\n","conv_2 = Conv2D(64, kernel_size=(3, 3), activation='relu') (maxp_1)\n","maxp_2 = MaxPooling2D(pool_size=(2, 2)) (conv_2)\n","conv_3 = Conv2D(128, kernel_size=(3, 3), activation='relu') (maxp_2)\n","maxp_3 = MaxPooling2D(pool_size=(2, 2)) (conv_3)\n","conv_4 = Conv2D(256, kernel_size=(3, 3), activation='relu') (maxp_3)\n","maxp_4 = MaxPooling2D(pool_size=(2, 2)) (conv_4)\n","\n","flatten = Flatten() (maxp_4)  # flatten is conventional layers heve weight in terms of matrix structure, so flattern convert to single dimension\n","\n","# fully connected layers\n","dense_1 = Dense(256, activation='relu') (flatten)\n","dense_2 = Dense(256, activation='relu') (flatten)\n","\n","dropout_1 = Dropout(0.5) (dense_1)\n","dropout_2 = Dropout(0.3) (dense_2)\n","\n","output_1 = Dense(5, activation='softmax', name='race_out') (dropout_1)\n","output_2 = Dense(1, activation='sigmoid', name='gender_out') (dropout_2)\n","\n","model = Model(inputs=[inputs], outputs=[output_1])\n","\n","model.compile(loss=[tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)], optimizer='rmsprop', metrics=['accuracy'])"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2022-07-21T11:56:37.155050Z","iopub.status.busy":"2022-07-21T11:56:37.154477Z","iopub.status.idle":"2022-07-21T11:56:37.164881Z","shell.execute_reply":"2022-07-21T11:56:37.163962Z","shell.execute_reply.started":"2022-07-21T11:56:37.155010Z"},"trusted":true},"outputs":[],"source":["model.summary()"]},{"cell_type":"code","execution_count":56,"metadata":{"execution":{"iopub.execute_input":"2022-07-21T13:40:16.255745Z","iopub.status.busy":"2022-07-21T13:40:16.255183Z","iopub.status.idle":"2022-07-21T13:40:16.818073Z","shell.execute_reply":"2022-07-21T13:40:16.814753Z","shell.execute_reply.started":"2022-07-21T13:40:16.255703Z"},"trusted":true},"outputs":[],"source":["plot_model(model)"]},{"cell_type":"code","execution_count":62,"metadata":{"execution":{"iopub.execute_input":"2022-07-21T13:44:56.319029Z","iopub.status.busy":"2022-07-21T13:44:56.318443Z","iopub.status.idle":"2022-07-21T13:44:56.325693Z","shell.execute_reply":"2022-07-21T13:44:56.324515Z","shell.execute_reply.started":"2022-07-21T13:44:56.318984Z"},"trusted":true},"outputs":[],"source":["checkpoint_path = '/working/cp_03.ckpt'\n","checkpoint_dir = os.path.dirname(checkpoint_path)\n","# Create a callback that saves the model's weights\n","cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n","                                                 save_weights_only=True,\n","                                                 verbose=1)"]},{"cell_type":"code","execution_count":65,"metadata":{"execution":{"iopub.execute_input":"2022-07-21T13:45:35.674375Z","iopub.status.busy":"2022-07-21T13:45:35.672799Z","iopub.status.idle":"2022-07-21T15:00:02.711455Z","shell.execute_reply":"2022-07-21T15:00:02.709655Z","shell.execute_reply.started":"2022-07-21T13:45:35.674308Z"},"trusted":true},"outputs":[],"source":["# train model\n","history = model.fit(x=X, y=[y_race], batch_size=32, epochs=16, validation_split=0.2, callbacks=[cp_callback]) # Pass callback to training"]},{"cell_type":"code","execution_count":66,"metadata":{"execution":{"iopub.execute_input":"2022-07-21T15:09:58.479071Z","iopub.status.busy":"2022-07-21T15:09:58.478415Z","iopub.status.idle":"2022-07-21T15:09:58.666924Z","shell.execute_reply":"2022-07-21T15:09:58.665612Z","shell.execute_reply.started":"2022-07-21T15:09:58.479019Z"},"trusted":true},"outputs":[],"source":["saved_model_path = '/working/saved_model_21Jul2022_race_02.h5'\n","model.save(saved_model_path)\n","\n","# saved_model_path = '/working/saved_model_21Jul2022_race_01.h5'\n","# model = tf.keras.models.load_model(saved_model_path)\n","# new_model.summary()"]},{"cell_type":"code","execution_count":76,"metadata":{"execution":{"iopub.execute_input":"2022-07-21T15:15:48.830440Z","iopub.status.busy":"2022-07-21T15:15:48.829197Z","iopub.status.idle":"2022-07-21T15:15:49.291119Z","shell.execute_reply":"2022-07-21T15:15:49.289928Z","shell.execute_reply.started":"2022-07-21T15:15:48.830377Z"},"trusted":true},"outputs":[],"source":["# plot results for gender\n","acc = history.history['race_out_accuracy']\n","val_acc = history.history['val_race_out_accuracy']\n","epochs = range(len(acc))    # can getting the number of epochs\n","\n","plt.plot(epochs, acc, 'b', label='Training Accuracy')        # 'b' is blue\n","plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')  # 'r' is red\n","plt.title('Accuracy Graph')\n","plt.legend()\n","plt.figure()\n","\n","loss = history.history['race_out_loss']\n","val_loss = history.history['val_race_out_loss']\n","\n","plt.plot(epochs, loss, 'b', label='Training Loss')\n","plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n","plt.title('Loss Graph')\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["### Prediction with Test Data"]},{"cell_type":"code","execution_count":75,"metadata":{"execution":{"iopub.execute_input":"2022-07-21T15:14:08.196174Z","iopub.status.busy":"2022-07-21T15:14:08.195597Z","iopub.status.idle":"2022-07-21T15:14:30.023142Z","shell.execute_reply":"2022-07-21T15:14:30.021657Z","shell.execute_reply.started":"2022-07-21T15:14:08.196131Z"},"trusted":true},"outputs":[],"source":["def predict_image(image_index, X, model):\n","    print(\"Original Race:\", race_dict[y_race[image_index]],)\n","    pred = model.predict(X[image_index].reshape(1, 128, 128, 1))\n","    pred_race = race_dict[list(pred[0][0]).index(np.max(pred[0][0]))]\n","    print(\"Predicted Race:\", pred_race,)\n","    plt.axis('off')\n","    plt.imshow(X[image_index].reshape(128, 128), cmap='gray')\n","    plt.show()\n","\n","vals = [index for index, file, age, gender, race in files.itertuples()]\n","for i, index in enumerate(np.random.choice(vals, size=15, replace=False)):\n","    predict_image(index, X, model)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
